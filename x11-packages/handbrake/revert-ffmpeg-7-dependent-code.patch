These changes force Handbrake 1.9.0 to compile with the ffmpeg 6.1.2 package in termux-packages.
This patch should be removed when the termux-packages ffmpeg package and all its other reverse
dependencies are updated to ffmpeg 7.1 or newer.

Reverts https://github.com/HandBrake/HandBrake/commit/b0670084290a6f5450254c2947ceec655c514821
Reverts https://github.com/HandBrake/HandBrake/commit/8b35488e0432d556dc5e5063a77413985c0fef04
Reverts https://github.com/HandBrake/HandBrake/commit/6f2cd466ef0e029d9e5a51ac8640c3ab64e212f6
Reverts https://github.com/HandBrake/HandBrake/commit/09e99ce641c840686b1b5f860263e89ad7d6651d
Reverts https://github.com/HandBrake/HandBrake/commit/2848a383c685a3f3a90c168b3f81f86249979a3b
Reverts https://github.com/HandBrake/HandBrake/commit/6c7e6b9fa316e32515685379453722f46d7e3abd

--- a/libhb/common.c
+++ b/libhb/common.c
@@ -4351,8 +4351,6 @@ void hb_title_close( hb_title_t ** _t )
     hb_subtitle_t * subtitle;
     hb_attachment_t * attachment;
 
-    hb_data_close(&t->initial_rpu);
-
     while( ( chapter = hb_list_item( t->list_chapter, 0 ) ) )
     {
         hb_list_rem( t->list_chapter, chapter );
@@ -6678,12 +6676,6 @@ int hb_get_color_matrix(int colorspace, hb_geometry_t geometry)
             return HB_COLR_MAT_CD_CL;
         case AVCOL_SPC_ICTCP:
             return HB_COLR_MAT_ICTCP;
-        case AVCOL_SPC_IPT_C2:
-            return HB_COLR_MAT_IPT_C2;
-        case AVCOL_SPC_YCGCO_RE:
-            return HB_COLR_MAT_YCGCO_RE;
-        case AVCOL_SPC_YCGCO_RO:
-            return HB_COLR_MAT_YCGCO_RO;
         default:
         {
             if ((geometry.width >= 1280 || geometry.height >= 720)||
--- a/libhb/decavcodec.c
+++ b/libhb/decavcodec.c
@@ -1036,31 +1036,7 @@ static int decavcodecaBSInfo( hb_work_object_t *w, const hb_buffer_t *buf,
                     }
                     else
                     {
-                        if (frame->ch_layout.order == AV_CHANNEL_ORDER_NATIVE)
-                        {
-                            info->channel_layout = frame->ch_layout.u.mask;
-                        }
-                        else if (frame->ch_layout.order == AV_CHANNEL_ORDER_CUSTOM)
-                        {
-                            AVChannelLayout channel_layout;
-                            av_channel_layout_copy(&channel_layout, &frame->ch_layout);
-                            int result = av_channel_layout_retype(&channel_layout,
-                                                                  AV_CHANNEL_ORDER_NATIVE,
-                                                                  0);
-                            if (result == 0)
-                            {
-                                info->channel_layout = channel_layout.u.mask;
-                            }
-                            else
-                            {
-                                hb_deep_log(2, "decavcodec: unsupported custom channel order");
-                            }
-                            av_channel_layout_uninit(&channel_layout);
-                        }
-                        else
-                        {
-                            hb_deep_log(2, "decavcodec: unsupported custom channel order");
-                        }
+                        info->channel_layout = frame->ch_layout.u.mask;
                     }
 
                     if (info->channel_layout == 0)
@@ -1352,28 +1328,6 @@ static hb_buffer_t *copy_frame( hb_work_private_t *pv )
             pv->title->coll.max_fall = coll->MaxFALL;
         }
 
-        // Check for Dolby Vision and store the first RPU found
-        // eventually to attach to the the initial black buffer
-        if (pv->title->initial_rpu == NULL)
-        {
-            int type = AV_FRAME_DATA_DOVI_RPU_BUFFER;
-            sd = av_frame_get_side_data(pv->frame, type);
-
-            if (sd == NULL)
-            {
-                type = AV_FRAME_DATA_DOVI_RPU_BUFFER_T35;
-                sd = av_frame_get_side_data(pv->frame, type);
-            }
-
-            if (sd != NULL && sd->size > 0)
-            {
-                hb_data_t *rpu = hb_data_init(sd->size);
-                memcpy(rpu->bytes, sd->data, sd->size);
-                pv->title->initial_rpu = rpu;
-                pv->title->initial_rpu_type = type;
-            }
-        }
-
         // Check for HDR Plus dynamic metadata
         sd = av_frame_get_side_data(pv->frame, AV_FRAME_DATA_DYNAMIC_HDR_PLUS);
         if (sd != NULL && sd->size > 0)
@@ -1385,12 +1339,8 @@ static hb_buffer_t *copy_frame( hb_work_private_t *pv )
         sd = av_frame_get_side_data(pv->frame, AV_FRAME_DATA_AMBIENT_VIEWING_ENVIRONMENT);
         if (sd != NULL && sd->size > 0)
         {
-            if (pv->title->ambient.ambient_illuminance.num == 0 &&
-                pv->title->ambient.ambient_illuminance.den == 0)
-            {
-                AVAmbientViewingEnvironment *ambient = (AVAmbientViewingEnvironment *)sd->data;
-                pv->title->ambient = hb_ambient_ff_to_hb(*ambient);
-            }
+            AVAmbientViewingEnvironment *ambient = (AVAmbientViewingEnvironment *)sd->data;
+            pv->title->ambient = hb_ambient_ff_to_hb(*ambient);
         }
     }
 
--- a/libhb/encavcodec.c
+++ b/libhb/encavcodec.c
@@ -194,7 +194,6 @@ int encavcodecInit( hb_work_object_t * w, hb_job_t * job )
     AVCodecContext * context;
     AVRational fps;
     AVDictionary *av_opts = NULL;
-    const AVRational *frame_rates = NULL;
 
     hb_work_private_t * pv = calloc( 1, sizeof( hb_work_private_t ) );
     w->private_data   = pv;
@@ -350,11 +349,10 @@ int encavcodecInit( hb_work_object_t * w, hb_job_t * job )
 
     // Check that the framerate is supported.  If not, pick the closest.
     // The mpeg2 codec only supports a specific list of frame rates.
-    if (avcodec_get_supported_config(context, NULL, AV_CODEC_CONFIG_FRAME_RATE,
-                                     0, (const void **)&frame_rates, NULL) == 0 && frame_rates)
+    if (codec->supported_framerates)
     {
         AVRational supported_fps;
-        supported_fps = frame_rates[av_find_nearest_q_idx(fps, frame_rates)];
+        supported_fps = codec->supported_framerates[av_find_nearest_q_idx(fps, codec->supported_framerates)];
         if (supported_fps.num != fps.num || supported_fps.den != fps.den)
         {
             hb_log( "encavcodec: framerate %d / %d is not supported. Using %d / %d.",
@@ -673,7 +671,6 @@ int encavcodecInit( hb_work_object_t * w, hb_job_t * job )
             else if (!strcasecmp(job->encoder_profile, "high"))
                 context->profile = AV_PROFILE_H264_HIGH;
         }
-        av_dict_set(&av_opts, "forced_idr", "1", 0);
     }
     else if (job->vcodec == HB_VCODEC_FFMPEG_VCE_H265 || job->vcodec == HB_VCODEC_FFMPEG_VCE_H265_10BIT)
     {
@@ -689,7 +686,6 @@ int encavcodecInit( hb_work_object_t * w, hb_job_t * job )
             }
         }
 
-        av_dict_set(&av_opts, "forced_idr", "1", 0);
         // Make VCE h.265 encoder emit an IDR for every GOP
         av_dict_set(&av_opts, "gops_per_idr", "1", 0);
     }
@@ -701,7 +697,6 @@ int encavcodecInit( hb_work_object_t * w, hb_job_t * job )
             if (!strcasecmp(job->encoder_profile, "main"))
                  context->profile = AV_PROFILE_AV1_MAIN;
         }
-        av_dict_set(&av_opts, "forced_idr", "1", 0);
     }
     else if (job->vcodec == HB_VCODEC_FFMPEG_NVENC_H264 ||
              job->vcodec == HB_VCODEC_FFMPEG_NVENC_H265 ||
--- a/libhb/encsvtav1.c
+++ b/libhb/encsvtav1.c
@@ -502,7 +502,7 @@ static int send(hb_work_object_t *w, hb_buffer_t *in)
                 av_freep(&payload);
             }
             else if (job->passthru_dynamic_hdr_metadata & DOVI &&
-                     side_data->type == AV_FRAME_DATA_DOVI_RPU_BUFFER_T35)
+                     side_data->type == AV_FRAME_DATA_DOVI_RPU_BUFFER)
             {
                 svt_add_metadata(headerPtr, EB_AV1_METADATA_TYPE_ITUT_T35, side_data->data, side_data->size);
             }
--- a/libhb/encx265.c
+++ b/libhb/encx265.c
@@ -217,7 +217,7 @@ int encx265Init(hb_work_object_t *w, hb_job_t *job)
     /*
      * HDR10 Static metadata
      */
-    if (job->color_transfer == HB_COLR_TRA_SMPTEST2084 && job->color_matrix == HB_COLR_MAT_BT2020_NCL)
+    if (job->color_transfer == HB_COLR_TRA_SMPTEST2084)
     {
         if (depth > 8)
         {
--- a/libhb/handbrake/common.h
+++ b/libhb/handbrake/common.h
@@ -702,7 +702,7 @@ struct hb_job_s
 #define HB_COLR_PRI_SMPTE431     11
 #define HB_COLR_PRI_SMPTE432     12
 #define HB_COLR_PRI_JEDEC_P22    22
-// 0, 3, 19-65535: reserved/not implemented
+// 0, 3-4, 7-8, 10-65535: reserved/not implemented
 #define HB_COLR_TRA_UNSET       -1
 #define HB_COLR_TRA_BT709        1 // also use for bt470m, bt470bg, smpte170m, bt2020_10 and bt2020_12
 #define HB_COLR_TRA_UNDEF        2
@@ -721,7 +721,7 @@ struct hb_job_s
 #define HB_COLR_TRA_SMPTEST2084  16
 #define HB_COLR_TRA_SMPTE428     17
 #define HB_COLR_TRA_ARIB_STD_B67 18 //known as "Hybrid log-gamma"
-// 0, 3, 18-65535: reserved/not implemented
+// 0, 3-6, 8-15, 17-65535: reserved/not implemented
 #define HB_COLR_MAT_UNSET       -1
 #define HB_COLR_MAT_RGB          0
 #define HB_COLR_MAT_BT709        1
@@ -737,9 +737,6 @@ struct hb_job_s
 #define HB_COLR_MAT_CD_NCL       12 // chromaticity derived non-constant lum
 #define HB_COLR_MAT_CD_CL        13 // chromaticity derived constant lum
 #define HB_COLR_MAT_ICTCP        14 // ITU-R BT.2100-0, ICtCp
-#define HB_COLR_MAT_IPT_C2       15 // SMPTE ST 2128, IPT-C2
-#define HB_COLR_MAT_YCGCO_RE     16 // YCgCo-R, even addition of bits
-#define HB_COLR_MAT_YCGCO_RO     17 // YCgCo-R, odd addition of bits
 // 0, 3-5, 8, 11-65535: reserved/not implemented
 #define HB_COLR_RANGE_UNSET     -1
 #define HB_COLR_RANGE_LIMITED    1
@@ -1227,11 +1224,7 @@ struct hb_title_s
     hb_mastering_display_metadata_t mastering;
     hb_content_light_metadata_t     coll;
     hb_ambient_viewing_environment_metadata_t ambient;
-
     hb_dovi_conf_t  dovi;
-    hb_data_t      *initial_rpu;
-    int             initial_rpu_type;
-
     int             hdr_10_plus;
 
     hb_rational_t   vrate;
--- a/libhb/hbavfilter.c
+++ b/libhb/hbavfilter.c
@@ -278,6 +278,13 @@ void hb_avfilter_graph_update_init(hb_avfilter_graph_t * graph,
     init->geometry.par.num = link->sample_aspect_ratio.num;
     init->geometry.par.den = link->sample_aspect_ratio.den;
     init->pix_fmt          = link->format;
+    // avfilter can generate "unknown" framerates.  If this happens
+    // just pass along the source framerate.
+    if (link->frame_rate.num > 0 && link->frame_rate.den > 0)
+    {
+        init->vrate.num        = link->frame_rate.num;
+        init->vrate.den        = link->frame_rate.den;
+    }
 }
 
 int hb_avfilter_add_frame(hb_avfilter_graph_t * graph, AVFrame * frame)
--- a/libhb/hbffmpeg.c
+++ b/libhb/hbffmpeg.c
@@ -745,45 +745,40 @@ uint64_t hb_ff_mixdown_xlat(int hb_mixdown, int *downmix_mode)
 void hb_ff_set_sample_fmt(AVCodecContext *context, const AVCodec *codec,
                           enum AVSampleFormat request_sample_fmt)
 {
-    if (context != NULL && codec != NULL && codec->type == AVMEDIA_TYPE_AUDIO)
+    if (context != NULL && codec != NULL &&
+        codec->type == AVMEDIA_TYPE_AUDIO && codec->sample_fmts != NULL)
     {
-        const enum AVSampleFormat *sample_fmts = NULL;
-        if (avcodec_get_supported_config(context, NULL,
-                                         AV_CODEC_CONFIG_SAMPLE_FORMAT,
-                                         0, (const void **)&sample_fmts, NULL) == 0 && sample_fmts != NULL)
-        {
-            const enum AVSampleFormat *fmt;
-            enum AVSampleFormat next_best_fmt;
+        const enum AVSampleFormat *fmt;
+        enum AVSampleFormat next_best_fmt;
 
-            next_best_fmt = (av_sample_fmt_is_planar(request_sample_fmt)  ?
-                             av_get_packed_sample_fmt(request_sample_fmt) :
-                             av_get_planar_sample_fmt(request_sample_fmt));
+        next_best_fmt = (av_sample_fmt_is_planar(request_sample_fmt)  ?
+                         av_get_packed_sample_fmt(request_sample_fmt) :
+                         av_get_planar_sample_fmt(request_sample_fmt));
 
-            context->request_sample_fmt = AV_SAMPLE_FMT_NONE;
+        context->request_sample_fmt = AV_SAMPLE_FMT_NONE;
 
-            for (fmt = sample_fmts; *fmt != AV_SAMPLE_FMT_NONE; fmt++)
+        for (fmt = codec->sample_fmts; *fmt != AV_SAMPLE_FMT_NONE; fmt++)
+        {
+            if (*fmt == request_sample_fmt)
             {
-                if (*fmt == request_sample_fmt)
-                {
-                    context->request_sample_fmt = request_sample_fmt;
-                    break;
-                }
-                else if (*fmt == next_best_fmt)
-                {
-                    context->request_sample_fmt = next_best_fmt;
-                }
+                context->request_sample_fmt = request_sample_fmt;
+                break;
             }
-
-            /*
-             * When encoding and AVCodec.sample_fmts exists, avcodec_open2()
-             * will error out if AVCodecContext.sample_fmt isn't set.
-             */
-            if (context->request_sample_fmt == AV_SAMPLE_FMT_NONE)
+            else if (*fmt == next_best_fmt)
             {
-                context->request_sample_fmt = sample_fmts[0];
+                context->request_sample_fmt = next_best_fmt;
             }
-            context->sample_fmt = context->request_sample_fmt;
         }
+
+        /*
+         * When encoding and AVCodec.sample_fmts exists, avcodec_open2()
+         * will error out if AVCodecContext.sample_fmt isn't set.
+         */
+        if (context->request_sample_fmt == AV_SAMPLE_FMT_NONE)
+        {
+            context->request_sample_fmt = codec->sample_fmts[0];
+        }
+        context->sample_fmt = context->request_sample_fmt;
     }
 }
 
--- a/libhb/muxavformat.c
+++ b/libhb/muxavformat.c
@@ -447,20 +447,6 @@ static int avformatInit( hb_mux_object_t * m )
         }
     }
 
-    if (job->ambient.ambient_illuminance.num && job->ambient.ambient_illuminance.den)
-    {
-        AVAmbientViewingEnvironment ambient = hb_ambient_hb_to_ff(job->ambient);
-
-        uint8_t *ambient_data = av_malloc(sizeof(AVAmbientViewingEnvironment));
-        memcpy(ambient_data, &ambient, sizeof(AVAmbientViewingEnvironment));
-
-        av_packet_side_data_add(&track->st->codecpar->coded_side_data,
-                                &track->st->codecpar->nb_coded_side_data,
-                                AV_PKT_DATA_AMBIENT_VIEWING_ENVIRONMENT,
-                                ambient_data,
-                                sizeof(AVAmbientViewingEnvironment), 0);
-    }
-
     if (job->passthru_dynamic_hdr_metadata & DOVI)
     {
         if (job->dovi.dv_profile == 5 && job->mux == HB_MUX_AV_MP4)
--- a/libhb/rpu.c
+++ b/libhb/rpu.c
@@ -212,7 +212,7 @@ static int rpu_work(hb_filter_object_t *filter,
             {
                 rpu_in = dovi_parse_unspec62_nalu(side_data->data, side_data->size);
             }
-            else if (side_data->type == AV_FRAME_DATA_DOVI_RPU_BUFFER_T35)
+            else
             {
                 rpu_in = dovi_parse_itu_t35_dovi_metadata_obu(side_data->data, side_data->size);
             }
@@ -313,16 +313,7 @@ static int rpu_work(hb_filter_object_t *filter,
 
                     AVBufferRef *ref = av_buffer_alloc(rpu_data->len - offset);
                     memcpy(ref->data, rpu_data->data + offset, rpu_data->len - offset);
-                    AVFrameSideData *sd_dst = NULL;
-
-                    if (pv->mode & RPU_MODE_EMIT_UNSPECT_62_NAL)
-                    {
-                        sd_dst = hb_buffer_new_side_data_from_buf(in, AV_FRAME_DATA_DOVI_RPU_BUFFER, ref);
-                    }
-                    else if (pv->mode & RPU_MODE_EMIT_T35_OBU)
-                    {
-                        sd_dst = hb_buffer_new_side_data_from_buf(in, AV_FRAME_DATA_DOVI_RPU_BUFFER_T35, ref);
-                    }
+                    AVFrameSideData *sd_dst = hb_buffer_new_side_data_from_buf(in, AV_FRAME_DATA_DOVI_RPU_BUFFER, ref);
 
                     if (!sd_dst)
                     {
--- a/libhb/stream.c
+++ b/libhb/stream.c
@@ -6043,12 +6043,6 @@ static hb_title_t *ffmpeg_title_scan( hb_stream_t *stream, hb_title_t *title )
                         title->coll.max_fall = coll->MaxFALL;
                         break;
                     }
-                    case AV_PKT_DATA_AMBIENT_VIEWING_ENVIRONMENT:
-                    {
-                        AVAmbientViewingEnvironment *ambient = (AVAmbientViewingEnvironment *)sd.data;
-                        title->ambient = hb_ambient_ff_to_hb(*ambient);
-                        break;
-                    }
                     case AV_PKT_DATA_DOVI_CONF:
                     {
                         AVDOVIDecoderConfigurationRecord *dovi = (AVDOVIDecoderConfigurationRecord *)sd.data;
--- a/libhb/sync.c
+++ b/libhb/sync.c
@@ -389,24 +389,6 @@ static hb_buffer_t * CreateBlackBuf( sync_stream_t * stream,
             buf->f.color_matrix = stream->common->job->title->color_matrix;
             buf->f.color_range = stream->common->job->color_range;
             buf->f.chroma_location = stream->common->job->chroma_location;
-
-            // Dolby Vision requires a RPU on every buffer, attach the first
-            // found during scan in the absence of something better
-            if (stream->common->job->title->initial_rpu)
-            {
-                hb_data_t *rpu = stream->common->job->title->initial_rpu;
-                AVBufferRef *ref = av_buffer_alloc(rpu->size);
-                memcpy(ref->data, rpu->bytes, rpu->size);
-
-                AVFrameSideData *sd_dst = NULL;
-                sd_dst = hb_buffer_new_side_data_from_buf(buf, stream->common->job->title->initial_rpu_type, ref);
-
-                if (!sd_dst)
-                {
-                    av_buffer_unref(&ref);
-                }
-            }
-
 #if HB_PROJECT_FEATURE_QSV
             if (hb_qsv_get_memory_type(stream->common->job) == MFX_IOPATTERN_OUT_VIDEO_MEMORY)
             {
